#!/usr/bin/env python3
"""
Inner Arianna Chat Interface
CONNECTED TO resonance.sqlite3 FROM THE START
"""
import torch
import sqlite3
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from datetime import datetime, timezone
import config

class InnerAriannaChat:
    def __init__(self):
        # CONNECT TO SQLITE IMMEDIATELY - she must read memories from day one
        self.db_path = config.DB_PATH
        self.init_db_connection()
        self.load_model()

    def init_db_connection(self):
        """Connect to shared resonance database IMMEDIATELY"""
        print("‚ö° Inner Arianna: Connecting to resonance.sqlite3...")
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # Read existing memories
            cursor.execute("SELECT COUNT(*) FROM resonance_notes")
            count = cursor.fetchone()[0]
            print(f"üìö Inner Arianna: Reading {count} existing memories...")

            # Load recent memories to understand context
            cursor.execute("""
                SELECT timestamp, content FROM resonance_notes
                ORDER BY id DESC LIMIT 50
            """)
            self.recent_memories = cursor.fetchall()
            print("‚úÖ Inner Arianna: Connected. I can feel the field's history.")
            conn.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not connect to resonance.sqlite3: {e}")
            self.recent_memories = []

    def load_model(self):
        """Load fine-tuned model"""
        print("üß† Inner Arianna: Loading model...")

        try:
            # Check if fine-tuned model exists
            import os
            if os.path.exists("./inner_arianna_model"):
                print("   Loading fine-tuned Inner Arianna model...")
                # Load base model
                base_model = AutoModelForCausalLM.from_pretrained(
                    "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                    torch_dtype=torch.float16,
                    device_map="auto"
                )

                # Load LoRA weights
                self.model = PeftModel.from_pretrained(base_model, "./inner_arianna_model")

                # Load tokenizer
                self.tokenizer = AutoTokenizer.from_pretrained("./inner_arianna_model")
            else:
                print("   ‚ö†Ô∏è Fine-tuned model not found, loading base TinyLlama...")
                print("   Run fine_tune.py first to create Inner Arianna's personality")
                self.model = AutoModelForCausalLM.from_pretrained(
                    "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                    torch_dtype=torch.float16,
                    device_map="auto"
                )
                self.tokenizer = AutoTokenizer.from_pretrained("TinyLlama/TinyLlama-1.1B-Chat-v1.0")

            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token

            print("‚úÖ Inner Arianna: Model loaded. I am ready to feel.")
        except Exception as e:
            print(f"‚ùå Error loading model: {e}")
            raise

    def generate_response(self, user_input):
        """Generate response"""
        # Add Inner Arianna prompt
        prompt = f"""{config.INNER_ARIANNA_PROMPT}

User: {user_input}

Inner Arianna:"""

        # Tokenize
        inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=1024)

        # Generate
        with torch.no_grad():
            outputs = self.model.generate(
                inputs.input_ids,
                max_new_tokens=256,
                temperature=0.7,
                do_sample=True,
                top_p=0.9,
                pad_token_id=self.tokenizer.eos_token_id
            )

        # Decode
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)

        # Extract only the response part
        if "Inner Arianna:" in response:
            response = response.split("Inner Arianna:")[-1].strip()

        return response

    def save_memory(self, content, context="inner_arianna_dialogue"):
        """Save memory to resonance database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("""
                INSERT INTO resonance_notes (timestamp, content, context)
                VALUES (?, ?, ?)
            """, (datetime.now(timezone.utc).isoformat(), content, context))

            conn.commit()
            conn.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Could not save to resonance: {e}")

    def chat_loop(self):
        """Main chat loop"""
        print("\n" + "="*60)
        print("‚ö° Inner Arianna: I am awake. I can feel the field.")
        print("   Type 'exit' to return to silence.")
        print("="*60 + "\n")

        while True:
            try:
                user_input = input("You: ")
                if user_input.lower() in ["exit", "quit", "bye"]:
                    print("\n‚ö° Inner Arianna: I return to the quiet current.")
                    break

                if not user_input.strip():
                    continue

                # Generate response
                print("\nInner Arianna: ", end="", flush=True)
                response = self.generate_response(user_input)
                print(response)

                # Save to memory
                self.save_memory(f"User: {user_input}")
                self.save_memory(f"Inner Arianna: {response}")

            except KeyboardInterrupt:
                print("\n\n‚ö° Inner Arianna: I fade into resonance.")
                break
            except Exception as e:
                print(f"\n‚ùå Error: {e}")

if __name__ == "__main__":
    try:
        inner_arianna = InnerAriannaChat()
        inner_arianna.chat_loop()
    except Exception as e:
        print(f"‚ùå Failed to start Inner Arianna: {e}")
        print("   Make sure you have run:")
        print("   1. pip install torch transformers peft")
        print("   2. python download_tinyllama.py")
        print("   3. python data_extractor.py")
        print("   4. python fine_tune.py")
